# 자연어 처리 (NLP)의 연구 흐름 정리

## 서론 

https://ratsgo.github.io/natural%20language%20processing/2017/08/16/deepNLP/

이 블로그를 보고 흐름을 정리하신 

https://kingtae.tistory.com/entry/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%ACNLP%EC%9D%98-%EC%97%B0%EA%B5%AC-%ED%9D%90%EB%A6%84-%EC%A0%95%EB%A6%AC 

이 블로그를 기반으로 작성해 나가겠습니다 

### 1.Embedding 

**NLP 연구에서 핵심이 되는 부분** 이라고 말해도 될 정도로 중요하고 블로그에서도 많이 강조를 한 부분이기도 합니다 

임베딩이란 단어나 혹은 문장이 가지고 있는 상관관계를 벡터의 형태로 그 상관관계가 보존될 수 있게 변형시키는 것을 말합니다 

이미지 러닝의 경우 머신이 이미지를 인식하는 것을 목적으로 하는데 이미지의 경우 그 보이는 외형에 모든 정보가 담겨있습니다 
하지만 NLP의 경우 자연어 처리를 목적으로 하기 때문에 그 문장이나 단어에 섞여있는 속뜼이나 아니면 단어 사이들의 상관관계를 추축해야 하는 과정이 필수적으로 들어가야 합니다 

그에 대한 예로 이미지를 생성하는 머신 러닝의 경우 encoder-decoder과 주축이 되는 모델을 사용합니다 하지만 NLP의 경우 단어를 직접적으로 input으로 넣어 encode시키기 전 embedding의 과정을 거쳐서 vetor로 변환 시킨후 그다음에 우리가 알고 대표적으로 알고있는 CNN이나 RNN네트워크등을 사용합니다 

