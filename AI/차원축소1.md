# SVD와 PCA, 그리고 잠재의미분석(LSA)

이번 포스트에서 **차원축소(dimension reduction)**기법으로 널리 쓰이고 있는 **특이값분해(Singular Value Decomposion)**와 **주성분분석(Principal Component Analysis)**에 대해 알아보도록 하겠습니다 마지막으론 이러한 기법이 **잠재의미분석(Latent Sematic Analysis)**와 어떻게 연결되는지도 이야기 해보도록하겠습니다 

## 주성분 분석

PCA는 데이터의 **분산(variance**)을 최대한 보존하면서 서로 직교하는 새 기저(축)를 찾아, 고차원 공간의 표본들을 선형 연관성이 없는 저차원 공간으로 변환하는 기법입니다
이를 그림으로 나타내면 아래와 같습니다. 3차원 공간에 있는 데이터들이 서로 수직인 두 개의 주성분(PC1, PC2)을 새로운 기저로, 선형변환된 것을 확인할 수 있습니다

![image](https://user-images.githubusercontent.com/80239748/159473710-37620ae8-f180-4144-901c-2423cd9ed424.png)

원 데이터의 분산을 최대화하는 새로운 기저를 찾는 목표를 달성하려면 우선 데이터 행렬A의 공분산 행렬부터 구해야 합니다 데이터가 각 변수별로 평균이 0으로 맞춰져 있을 때 공분산 행렬은 아래와 같이 구합니다 

![image](https://user-images.githubusercontent.com/80239748/159474046-b861e2ae-7478-440d-9e2e-3de7475dc852.png)

PCA의 새로운 축을 찾기 위해서는 위 공분산행렬을 아래처럼 *고유분해(Eigen decompositoion)*를 수행해주어야 합니다 아래 식에서 A는 대각성분이 공분산행렬의 고유 값이고 나머지 요소는 0인 행렬M,U는 열벡터가 공분산행렬 AA_T의 고유벡터로 이뤄진 행렬입니다 

![image](https://user-images.githubusercontent.com/80239748/159474586-de190fbd-50cc-4de1-9e34-4acfa442a37e.png)

